---
title: "Scraping Cran Task View by Topic"
author: "Madison Volpe"
date: "10/2/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Necessary Packages 

```{r message=FALSE}
library(plyr)
library(purrr)
library(tidyverse)
library(XML)
library(rvest)
library(RSelenium)
library(RCurl)
```

# Bayesian

## Pull list of Bayesian Packages from CTV 

```{r}
url <- "https://cran.r-project.org/web/views/Bayesian.html" 

BayesianPackages <-url %>%
                  read_html()%>%
                  html_nodes(xpath = "/html/body/ul[1]/li")  %>% #unique xpath to pull in all individually
                  html_text()

BayesianPackages # we now have all Bayesian Packages listed on the webpage 
```

## Make dataframe 

```{r}
BayesianPackages <- data.frame(BayesianPackages)
names(BayesianPackages) <- "Packages"
BayesianPackages$Packages <- as.character(BayesianPackages$Packages)
```

## Now we will construct URLs for each package

```{r}
baseURL <- "https://cran.r-project.org/web/packages/"

URLs <- paste(baseURL, BayesianPackages$Packages, "/index.html", sep = "") #makes URLs that you can navigate to

URLs <- data.frame(URLs)

URLs$URLs <- as.character(URLs$URLs)

BayesianPackages <- cbind(BayesianPackages, URLs)

```


## Loop to grab HTML of each URL (1 per package)

```{r}
start.time <- Sys.time()

mylist.names <- BayesianPackages$Packages
HTMLs <- as.list(rep(NA, length(mylist.names)))
names(HTMLs) <- mylist.names

for(i in 1:nrow(URLs)){
  HTMLs[[i]] <- getURL(URLs$URLs[i])
}

end.time <- Sys.time()

end.time - start.time

save(HTMLs, file = "HTMLs.rda")
load(file = "HTMLs.rda")
```

## Parse HTMLs 

### PackageDescriptions

```{r}
#Scrape Package Descriptions 
mylist.names <- BayesianPackages$Packages
PackageDesc <- as.list(rep(NA, length(mylist.names)))
names(PackageDesc) <- mylist.names

for(i in 1:length(HTMLs)){
  PackageDesc[[i]] <-HTMLs[[i]] %>%
                      read_html()%>%
                      html_nodes(xpath = "/html/body/p[1]") %>%
                      html_text()
}

#Clean Package Descriptions
for(i in 1:length(PackageDesc)){
  PackageDesc[[i]] <- PackageDesc[[i]] %>%
                      str_replace_all("\n", "") %>%
                      str_replace_all("\\s+", " ")%>%
                      str_replace_all("^\\s", "") %>%
                      str_replace_all("\\s$", "")
}

#Make dataframe
PackageDesc<- map_df(PackageDesc, ~as.data.frame(.x), .id="Package")
names(PackageDesc) <- c("Package","PackageDescription")

## Drop "Your browser sent a request that this server could not understand." - these are for CORE Packages 

PackageDesc$PackageDescription <- as.character(PackageDesc$PackageDescription)

PackageDesc <- PackageDesc %>%
  filter(PackageDescription != "Your browser sent a request that this server could not understand.")
```

### Summary Table

```{r}
#Scrape Package Summaries
mylist.names <- BayesianPackages$Packages
PackageSummaries <- as.list(rep(NA, length(mylist.names)))
names(PackageSummaries) <- mylist.names

for(i in 1:length(HTMLs)){
  PackageSummaries[[i]] <-HTMLs[[i]] %>%
                      read_html()%>%
                      html_nodes(xpath = "//table[@summary][1]") %>%
                      html_table() %>%
                      data.frame(stringsAsFactors = FALSE)
}

#Remove empty dataframes from the list (Core Packages)
PackageSummaries <-PackageSummaries[sapply(PackageSummaries, function(x) dim(x)[1]) > 0]

#Convert dataframes to useable format 
for(i in 1:length(PackageSummaries)){
  PackageSummaries[[i]]<-data.frame(split(PackageSummaries[[i]][1:nrow(PackageSummaries[[i]]), 2],PackageSummaries[[i]][1:nrow(PackageSummaries[[i]]),1]))
} 

#Unified dataframe
PackageSummaries<- rbind.fill(PackageSummaries)
```

##Reverse Dependencies 

```{r}
#Scrape Reverse Dependencies
mylist.names <- BayesianPackages$Packages
ReverseDepends <- as.list(rep(NA, length(mylist.names)))
names(ReverseDepends) <- mylist.names

for(i in 1:length(HTMLs)){
  ReverseDepends[[i]] <-HTMLs[[i]] %>%
                      read_html()%>%
                      html_nodes(xpath = "//tr/td[contains(text(), 'Reverse')]/ancestor::table") %>%
                      html_table() %>%
                      data.frame(stringsAsFactors = FALSE)
}

#Remove empty dataframes from the list (Core Packages)
ReverseDepends <- ReverseDepends[sapply(ReverseDepends, function(x) dim(x)[1]) > 0]

#Convert dataframes to useable format 
for(i in 1:length(ReverseDepends)){
  ReverseDepends[[i]]<-data.frame(split(ReverseDepends[[i]][1:nrow(ReverseDepends[[i]]), 2],ReverseDepends[[i]][1:nrow(ReverseDepends[[i]]),1]))
} 

#Make into one usable dataframe 
ReverseDepends <- map_df(ReverseDepends, ~as.data.frame(.x), .id="Package")
```

## Create Base Table 

```{r}
BayesianBase <-cbind(PackageDesc, PackageSummaries)
BayesianBase <- left_join(BayesianBase, ReverseDepends)
```

```{r}
rm(BayesianPackages, PackageDesc, PackageSummaries, ReverseDepends)
```

## Clean Base Table 

```{r}
 BayesianBase <- BayesianBase %>%
  dplyr::select(-Citation., -CRAN.checks., -License., -NeedsCompilation., -Materials., -Copyright., - Contact., -Priority.)
```

## Create Dependencies Table 

```{r}
BayesianDependencies <- BayesianBase %>%
    select(Package, Depends.) %>%
    mutate(Depends. = strsplit(as.character(Depends.), ",")) %>% 
    unnest(Depends.)

names(BayesianDependencies)[2] <- "Dependencies"
BayesianDependencies$Dependencies <- trimws(BayesianDependencies$Dependencies)

BayesianDependencies <- BayesianDependencies %>%
  filter(!is.na(Dependencies))

BayesianDependencies <- BayesianDependencies %>%
  filter(!grepl(pattern = "^R", Dependencies))
``` 

## Create In Views Table 

```{r}
BayesianInViews <- BayesianBase %>%
  select(Package, In.views.) %>%
  mutate(In.views. = strsplit(as.character(In.views.), ","))%>%
  unnest(In.views.)

names(BayesianInViews)[2] <- "InViews"
BayesianInViews$InViews <- trimws(BayesianInViews$InViews)

BayesianInViews <- BayesianInViews %>%
  filter(!is.na(InViews))
```

## Create Imports

## Create LinkingTo

## Create Suggests 

## Create Enhances

## Create Reverse Depends

## Create Reverse Imports

## Creeate Reverse Suggests

## Create Reverse linking to 

## Create Reverse enhances 

## 